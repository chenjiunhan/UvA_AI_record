{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P($m_{th}$ experiment gives significant result | $m$ experiments lacking power to reject $H_0$)\n",
    "\n",
    "= $(1-\\alpha)^{m-1}\\alpha$\n",
    "\n",
    "P(at least one significant result | $m$ experiments lacking power to reject $H_0$)\n",
    "\n",
    "= $\\alpha + (1-\\alpha)\\alpha + (1-\\alpha)^2\\alpha + ... + (1-\\alpha)^{m-1}\\alpha$\n",
    "\n",
    "= $\\frac{\\alpha(1 - (1 - \\alpha)^m)}{1 - (1 - \\alpha)}$\n",
    "\n",
    "= $1 - (1 - \\alpha)^m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import numpy as np\n",
    "NUM_SAMPLE = 5000\n",
    "SAMPLE_LENGTH = 5\n",
    "GMAX = 3\n",
    "\n",
    "# randomly generate sample\n",
    "P = np.random.randint(GMAX, size=(NUM_SAMPLE, SAMPLE_LENGTH))\n",
    "E = np.random.randint(GMAX, size=(NUM_SAMPLE, SAMPLE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Display ranking of P and E:\n",
      "\n",
      "P\n",
      " [[1 0 2 2 1]\n",
      " [0 0 2 2 2]\n",
      " [1 2 2 1 0]\n",
      " ..., \n",
      " [0 0 2 0 1]\n",
      " [0 0 0 1 2]\n",
      " [0 0 1 2 0]] \n",
      "\n",
      "Number of ranking of P: 5000 \n",
      "\n",
      "E\n",
      " [[1 1 2 0 2]\n",
      " [1 1 0 0 1]\n",
      " [1 0 1 0 0]\n",
      " ..., \n",
      " [1 1 2 2 0]\n",
      " [0 2 1 2 0]\n",
      " [1 1 2 2 1]] \n",
      "\n",
      "Number of ranking of E: 5000 \n",
      "\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('Display ranking of P and E:\\n')\n",
    "\n",
    "print('P\\n', P, '\\n\\nNumber of ranking of P:', len(P), '\\n')\n",
    "print('E\\n', E, '\\n\\nNumber of ranking of E:', len(E), '\\n') \n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing precision\n",
    "def precision(ranking):\n",
    "    counter_rank = Counter(ranking)\n",
    "    precision = (counter_rank[1] + counter_rank[2]) / sum(counter_rank.values())    \n",
    "    return precision\n",
    "\n",
    "P_precision = np.array([])\n",
    "E_precision = np.array([])\n",
    "\n",
    "for ranking in P:    \n",
    "    P_precision = np.append(P_precision, precision(ranking))\n",
    "    \n",
    "for ranking in E:    \n",
    "    E_precision = np.append(E_precision, precision(ranking))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Calculate precision for P and E:\n",
      "\n",
      "Precision for P:  [ 0.8  0.6  0.8 ...,  0.4  0.4  0.4]\n",
      "Length of precision for P:  5000\n",
      "\n",
      "Precision for E:  [ 0.8  0.6  0.4 ...,  0.8  0.6  1. ]\n",
      "Length of precision for E:  5000\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('Calculate precision for P and E:\\n')\n",
    "\n",
    "print('Precision for P: ', P_precision)\n",
    "print('Length of precision for P: ', len(P_precision))\n",
    "print()\n",
    "print('Precision for E: ', E_precision)\n",
    "print('Length of precision for E: ', len(E_precision))\n",
    "\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NDCG\n",
    "def NDCG(ranking): \n",
    "    DCG_summation = 0\n",
    "    NDCG_summation = 0    \n",
    "    \n",
    "    # sort ranking for calculating NDCG\n",
    "    sort_ranking = np.sort(ranking)[::-1]\n",
    "        \n",
    "    # calculate DCG and NDCG summation\n",
    "    for i in range(len(ranking)):        \n",
    "        DCG_summation += (2 ** ranking[i] - 1) / np.log2(1 + (i+1))\n",
    "        NDCG_summation += (2 ** sort_ranking[i] - 1) / np.log2(1 + (i+1))               \n",
    "            \n",
    "    # if NDCG summation is 0.0, DCG will be 0 too. So we can assign NDCG value as 0.\n",
    "    if NDCG_summation - 0.0 < 0.000001:\n",
    "        NDCG = 0.0\n",
    "    else:\n",
    "        NDCG = DCG_summation / NDCG_summation  \n",
    "    \n",
    "    return DCG_summation, NDCG\n",
    "\n",
    "P_NDCG = np.array([])\n",
    "E_NDCG = np.array([])\n",
    "\n",
    "# calculate NDCG\n",
    "for ranking in P:\n",
    "    DCG_one, NDCG_one = NDCG(ranking)\n",
    "    P_NDCG = np.append(P_NDCG, NDCG_one)\n",
    "    \n",
    "for ranking in E:\n",
    "    DCG_one, NDCG_one = NDCG(ranking)\n",
    "    E_NDCG = np.append(E_NDCG, NDCG_one)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Calculate NDCG for P and E:\n",
      "\n",
      "NDCG for P:  [ 0.71759372  0.6182885   0.82828095 ...,  0.51966106  0.4382445\n",
      "  0.49354567]\n",
      "Length of NDCG for P:  5000\n",
      "Max value of NDCG for P:  1.0\n",
      "\n",
      "NDCG for E:  [ 0.73693026  0.94690243  0.91972079 ...,  0.75950638  0.68328628\n",
      "  0.77448719]\n",
      "Length of NDCG for E:  5000\n",
      "Max value of NDCG for E:  1.0\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "\n",
    "print('Calculate NDCG for P and E:\\n')\n",
    "\n",
    "print('NDCG for P: ', P_NDCG)\n",
    "print('Length of NDCG for P: ', len(P_NDCG))\n",
    "print('Max value of NDCG for P: ', np.max(P_NDCG))\n",
    "\n",
    "print()\n",
    "\n",
    "print('NDCG for E: ', E_NDCG)\n",
    "print('Length of NDCG for E: ', len(E_NDCG))\n",
    "print('Max value of NDCG for E: ', np.max(E_NDCG))\n",
    "\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ERR\n",
    "\n",
    "# function to calculate R from relevance\n",
    "def g2R(g):\n",
    "    global GMAX\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(GMAX, g)\n",
    "    \n",
    "    return (2 ** g - 1) / (2 ** GMAX)\n",
    "\n",
    "# function to calculate ERR\n",
    "def ERR(rank_array):\n",
    "    summation = 0\n",
    "        \n",
    "    for g in range(len(rank_array)):                \n",
    "        \n",
    "        prod = 1        \n",
    "        for i in range(g - 1):             \n",
    "            prod *= 1 - g2R(rank_array[i])                        \n",
    "            \n",
    "        summation += prod * g2R(rank_array[g]) / (g + 1)                \n",
    "        \n",
    "    ERR = summation\n",
    "    return ERR\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_ERR = np.array([])\n",
    "E_ERR = np.array([])\n",
    "\n",
    "for ranking in P:\n",
    "    ERR_one = ERR(ranking)\n",
    "    P_ERR = np.append(P_ERR, ERR_one)\n",
    "    \n",
    "for ranking in E:\n",
    "    ERR_one = ERR(ranking)\n",
    "    E_ERR = np.append(E_ERR, ERR_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Calculate ERR for P and E:\n",
      "\n",
      "ERR for P:  [ 0.33007812  0.265625    0.43896484 ...,  0.140625    0.10625     0.13541667]\n",
      "Length of ERR for P:  5000\n",
      "\n",
      "ERR for E:  [ 0.33276367  0.20664062  0.16145833 ...,  0.36865234  0.28776042\n",
      "  0.38061523]\n",
      "Length of ERR for E:  5000\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "\n",
    "print('Calculate ERR for P and E:\\n')\n",
    "\n",
    "print('ERR for P: ', P_ERR)\n",
    "print('Length of ERR for P: ', len(P_ERR))\n",
    "\n",
    "print()\n",
    "\n",
    "print('ERR for E: ', E_ERR)\n",
    "print('Length of ERR for E: ', len(E_ERR))\n",
    "\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference of measure\n",
    "measure_precision = E_precision - P_precision\n",
    "measure_NDCG = E_NDCG - P_NDCG\n",
    "measure_ERR = E_ERR - P_ERR\n",
    "\n",
    "# indices which E outperformed P.\n",
    "measure_intersect_idx = np.intersect1d(np.intersect1d(np.where(measure_precision > 0)[0], np.where(measure_NDCG > 0)[0]), np.where(measure_ERR > 0)[0])\n",
    "\n",
    "# P_intersect and E_intersect is for considering only E outperformed P.\n",
    "# Remove sample which Measure P >= Measure E\n",
    "P_intersect = P[measure_intersect_idx]\n",
    "E_intersect = E[measure_intersect_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "measure precision:  [ 0.   0.  -0.4 ...,  0.4  0.2  0.6]\n",
      "measure NDCG:  [ 0.01933654  0.32861393  0.09143984 ...,  0.23984532  0.24504179\n",
      "  0.28094152]\n",
      "measure_ERR:  [ 0.00268555 -0.05898438 -0.27750651 ...,  0.22802734  0.18151042\n",
      "  0.24519857]\n",
      "\n",
      "measure intersect idx:  [   5    8   15 ..., 4997 4998 4999]\n",
      "\n",
      "P intersect: \n",
      " [[0 2 0 1 0]\n",
      " [2 0 0 0 1]\n",
      " [0 1 1 1 2]\n",
      " ..., \n",
      " [0 0 2 0 1]\n",
      " [0 0 0 1 2]\n",
      " [0 0 1 2 0]]\n",
      "Length of P intersect:  1232\n",
      "\n",
      "E intersect: \n",
      " [[2 1 0 0 1]\n",
      " [2 0 1 0 1]\n",
      " [1 2 2 2 2]\n",
      " ..., \n",
      " [1 1 2 2 0]\n",
      " [0 2 1 2 0]\n",
      " [1 1 2 2 1]]\n",
      "Length of E intersect:  1232\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('measure precision: ', measure_precision)\n",
    "print('measure NDCG: ', measure_NDCG)\n",
    "print('measure_ERR: ', measure_ERR)\n",
    "\n",
    "print()\n",
    "\n",
    "# indices which E outperformed P.\n",
    "print('measure intersect idx: ', measure_intersect_idx)\n",
    "\n",
    "print()\n",
    "\n",
    "# Display sample which Measure P >= Measure E\n",
    "print('P intersect: \\n', P_intersect)\n",
    "print('Length of P intersect: ', len(P_intersect))\n",
    "\n",
    "print()\n",
    "\n",
    "print('E intersect: \\n', E_intersect)\n",
    "print('Length of E intersect: ', len(E_intersect))\n",
    "\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team Draft Interleaving\n",
    "\n",
    "# interleaved ranking\n",
    "interleaved_ranking = np.ndarray((len(P), SAMPLE_LENGTH * 2), dtype=int)\n",
    "\n",
    "# for recording documents in ranking should be credited to P or E\n",
    "interleaved_PE = np.ndarray((len(P), SAMPLE_LENGTH * 2), dtype=int)\n",
    "\n",
    "# We assume P, E retrieve different documents and we don't have docID. \n",
    "# So return TEAM_P and TEAM_E is not necessary.\n",
    "\n",
    "for count_sample in range(len(P)):\n",
    "    count_team_P = 0\n",
    "    count_team_E = 0    \n",
    "    \n",
    "    count_while_idx = -1\n",
    "    while count_team_P < SAMPLE_LENGTH or count_team_E < SAMPLE_LENGTH:\n",
    "        count_while_idx += 1\n",
    "        \n",
    "        if count_team_P < count_team_E or (count_team_P == count_team_E and np.random.randint(2) == 1):\n",
    "            P_idx = count_team_P\n",
    "            interleaved_ranking[count_sample][count_while_idx] = P[count_sample][P_idx]\n",
    "            count_team_P += 1\n",
    "            interleaved_PE[count_sample][count_while_idx] = 0\n",
    "            \n",
    "        else:\n",
    "            E_idx = count_team_E\n",
    "            interleaved_ranking[count_sample][count_while_idx] = E[count_sample][E_idx]\n",
    "            count_team_E += 1\n",
    "            interleaved_PE[count_sample][count_while_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Interleaved ranking: \n",
      " [[1 1 0 ..., 0 2 1]\n",
      " [1 0 1 ..., 2 1 2]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [1 0 0 ..., 2 1 0]\n",
      " [0 0 2 ..., 1 2 0]\n",
      " [0 1 0 ..., 2 1 0]]\n",
      "\n",
      "Length of one interleaved ranking:  10\n",
      "Length of all interleaved rankings:  5000\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('Interleaved ranking: \\n', interleaved_ranking)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Length of one interleaved ranking: ', len(interleaved_ranking[0]))\n",
    "print('Length of all interleaved rankings: ', len(interleaved_ranking))\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex = open('YandexRelPredChallenge.txt', 'r')\n",
    "\n",
    "# count number of query and click for calculating RCM\n",
    "count_Q = 0\n",
    "count_C = 0\n",
    "\n",
    "# for sigma_uq of SDBN\n",
    "count_uq_dict = {}\n",
    "count_uq_last_dict = {}\n",
    "sigma_uq = {}\n",
    "\n",
    "# for converting N, R, HR to sigma_uq\n",
    "sigma_N = 0\n",
    "sigma_R = 0\n",
    "sigma_HR = 0\n",
    "count_R = 0\n",
    "count_HR = 0\n",
    "\n",
    "# for checking if one click is the last click of one query\n",
    "previous_typeOfAction = None\n",
    "last_queryID = None\n",
    "last_URLID = None\n",
    "\n",
    "# processing yandex for calculating parameters of RCM and SDBN\n",
    "for line in yandex:\n",
    "    count += 1\n",
    "    \n",
    "    line_split = line.split('\\t')\n",
    "    \n",
    "    typeOfAction = line_split[2]\n",
    "    \n",
    "    if typeOfAction == 'Q':\n",
    "        \n",
    "        if previous_typeOfAction == 'C':\n",
    "            if (last_queryID, last_URLID) in count_uq_last_dict:\n",
    "                count_uq_last_dict[(last_queryID, last_URLID)] += 1\n",
    "            else: \n",
    "                count_uq_last_dict[(last_queryID, last_URLID)] = 1\n",
    "                \n",
    "        count_Q += 1\n",
    "        \n",
    "        sessionID = line_split[0]\n",
    "        timePassed = line_split[1]\n",
    "        queryID = line_split[3]\n",
    "        regionID = line_split[4]\n",
    "        listOfURLs = line_split[5:]\n",
    "        listOfURLs[-1] = listOfURLs[-1][:-1]\n",
    "        \n",
    "        last_queryID = queryID        \n",
    "        \n",
    "    elif typeOfAction == 'C':\n",
    "        count_C += 1\n",
    "        \n",
    "        sessionID = line_split[0]\n",
    "        timePassed = line_split[1]        \n",
    "        URLID = line_split[3]    \n",
    "        URLID = URLID[:-1]        \n",
    "            \n",
    "        last_URLID = URLID\n",
    "            \n",
    "        if (last_queryID, URLID) in count_uq_dict:\n",
    "            count_uq_dict[(last_queryID, URLID)] += 1\n",
    "        else: \n",
    "            count_uq_dict[(last_queryID, URLID)] = 1\n",
    "    \n",
    "    previous_typeOfAction = typeOfAction\n",
    "    \n",
    "    \n",
    "for idx, denominator in count_uq_dict.items():\n",
    "    \n",
    "    if idx in count_uq_last_dict:\n",
    "        nominator = count_uq_last_dict[idx]\n",
    "    else:\n",
    "        nominator = 0.0\n",
    "    \n",
    "    sigma = nominator / denominator\n",
    "    \n",
    "    sigma_uq[idx] = sigma\n",
    "    \n",
    "    # define sigma > 0.8 as HR\n",
    "    if sigma > 0.8:\n",
    "        #relevance = 2\n",
    "        sigma_HR = (count_HR * sigma_HR + sigma) / (count_HR + 1)\n",
    "        count_HR += 1\n",
    "        \n",
    "    # define sigma >= 0 as R, at least the document is clicked after reading snippet.\n",
    "    else:\n",
    "        #relevance = 1\n",
    "        sigma_R = (count_R * sigma_R + sigma) / (count_R + 1)\n",
    "        count_R += 1    \n",
    "        \n",
    "    # if index(document-query pair) is not in sigma_uq, relevance will be 0 for model.\n",
    "    \n",
    "num_shown_doc = count_Q * 10\n",
    "RCM_p = count_C / num_shown_doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "RCM probability:  0.13445559411047547\n",
      "\n",
      "sigma for N:  0\n",
      "sigma for R:  0.06145912887528477\n",
      "sigma for HR:  0.999079479392326\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('RCM probability: ', RCM_p)\n",
    "\n",
    "print()\n",
    "\n",
    "print('sigma for N: ', sigma_N)\n",
    "print('sigma for R: ', sigma_R)\n",
    "print('sigma for HR: ', sigma_HR)\n",
    "\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert relevance to sigma for SDBN\n",
    "def g2Sigma(g):\n",
    "    global sigma_N, sigma_R, sigma_HR\n",
    "    if g == 2:\n",
    "        return sigma_HR\n",
    "    elif g == 1:\n",
    "        return sigma_R    \n",
    "    elif g == 0:\n",
    "        return sigma_N\n",
    "    \n",
    "    raise AssertionError()\n",
    "    \n",
    "# RCM    \n",
    "def RCM(ranking, p):\n",
    "    clicked_ranking = []    \n",
    "    \n",
    "    for idx, relevance in enumerate(ranking):\n",
    "        if np.random.rand() <= p:\n",
    "            clicked_ranking += [1]\n",
    "        else:\n",
    "            clicked_ranking += [0]\n",
    "            \n",
    "    return clicked_ranking\n",
    "        \n",
    "# SDBN\n",
    "def SDBN(ranking):\n",
    "    global sigma_N, sigma_R, sigma_HR\n",
    "    clicked_ranking = []\n",
    "    \n",
    "    for idx, relevance in enumerate(ranking):        \n",
    "        \n",
    "        # SDBN gamma = 1\n",
    "        P_E = 1\n",
    "        P_A = g2R(relevance)\n",
    "        P_C = P_E * P_A\n",
    "        \n",
    "        if np.random.rand() <= P_C:\n",
    "            clicked_ranking += [1]\n",
    "            P_S = g2Sigma(relevance)\n",
    "            if np.random.rand() <= P_S:\n",
    "                if idx < len(ranking) - 1:\n",
    "                    clicked_ranking += (len(ranking) - 1 - idx) * [0]\n",
    "                break\n",
    "        else:\n",
    "            clicked_ranking += [0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    return clicked_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Test click models(1 means clicked): \n",
      "\n",
      "RCM: [0, 1, 0, 1, 0]\n",
      "\n",
      "SDBN [0, 0, 0, 1, 0]\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('Test click models(1 means clicked): \\n')\n",
    "\n",
    "print('RCM:', RCM(P[0], RCM_p))\n",
    "\n",
    "print()\n",
    "\n",
    "print('SDBN', SDBN(P[0]))\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521 1497 1982 1890 1965 1145\n"
     ]
    }
   ],
   "source": [
    "RCM_P_WIN = 0\n",
    "RCM_E_WIN = 0\n",
    "RCM_TIE = 0\n",
    "\n",
    "SDBN_P_WIN = 0\n",
    "SDBN_E_WIN = 0\n",
    "SDBN_TIE = 0\n",
    "\n",
    "for idx, interleave in enumerate(interleaved_ranking):    \n",
    "    RCM_simulation = RCM(interleave, RCM_p)\n",
    "    SDBN_simulation = SDBN(interleave)\n",
    "    \n",
    "    RCM_clicked_index = np.where(np.array(RCM_simulation) == 1)\n",
    "    SDBN_clicked_index = np.where(np.array(SDBN_simulation) == 1)\n",
    "    \n",
    "    RCM_winners = interleaved_PE[idx][RCM_clicked_index]\n",
    "    SDBN_winners = interleaved_PE[idx][SDBN_clicked_index]\n",
    "    \n",
    "    RCM_count_P_winner = len(np.where(RCM_winners == 0)[0])\n",
    "    RCM_count_E_winner = len(np.where(RCM_winners == 1)[0])\n",
    "    \n",
    "    SDBN_count_P_winner = len(np.where(SDBN_winners == 0)[0])\n",
    "    SDBN_count_E_winner = len(np.where(SDBN_winners == 1)[0])\n",
    "    \n",
    "    if RCM_count_P_winner > RCM_count_E_winner:\n",
    "        RCM_P_WIN += 1\n",
    "    elif RCM_count_P_winner < RCM_count_E_winner:\n",
    "        RCM_E_WIN += 1\n",
    "    else:\n",
    "        RCM_TIE += 1\n",
    "        \n",
    "    if SDBN_count_P_winner > SDBN_count_E_winner:\n",
    "        SDBN_P_WIN += 1\n",
    "    elif SDBN_count_P_winner < SDBN_count_E_winner:\n",
    "        SDBN_E_WIN += 1\n",
    "    else:\n",
    "        SDBN_TIE += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------TEST UNIT--------------------\n",
      "\n",
      "Simulate results: \n",
      "\n",
      "Count RCM P win:  1521\n",
      "Count RCM E win:  1497\n",
      "Count RCM tie:  1982\n",
      "Count SDBN P win:  1890\n",
      "Count SDBN E win:  1965\n",
      "Count SDBN tie:  1145\n",
      "\n",
      "--------------END OF TEST UNIT---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST UNIT\n",
    "print('----------------TEST UNIT--------------------\\n')\n",
    "print('Simulate results: \\n')\n",
    "print('Count RCM P win: ', RCM_P_WIN)\n",
    "print('Count RCM E win: ', RCM_E_WIN)\n",
    "print('Count RCM tie: ', RCM_TIE)\n",
    "print('Count SDBN P win: ', SDBN_P_WIN)\n",
    "print('Count SDBN E win: ', SDBN_E_WIN)\n",
    "print('Count SDBN tie: ', SDBN_TIE)\n",
    "print('\\n--------------END OF TEST UNIT---------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
